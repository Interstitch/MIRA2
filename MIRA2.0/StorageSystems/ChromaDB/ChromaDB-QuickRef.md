# ChromaDB Quick Reference - MIRA 2.0

## ğŸš€ Setup Checklist

### Dependencies
```bash
pip install chromadb==0.4.24
pip install pysqlite3-binary==0.5.0
pip install sentence-transformers==2.2.2
pip install faiss-cpu==1.7.4  # or faiss-gpu for GPU
```

### SQLite Fix (Required on most systems)
```python
# Put at TOP of any file using ChromaDB
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
```

## ğŸ“¦ Collection Names & Storage Layout

### Physical Storage in .mira Directory
```
~/.mira/
â”œâ”€â”€ databases/
â”‚   â”œâ”€â”€ chromadb/           # ChromaDB vector storage
â”‚   â”‚   â”œâ”€â”€ chroma.sqlite3  # Main database
â”‚   â”‚   â””â”€â”€ [collection_id]/# Collection data folders
â”‚   â”‚       â”œâ”€â”€ data_level0.bin
â”‚   â”‚       â”œâ”€â”€ header.bin
â”‚   â”‚       â”œâ”€â”€ index_metadata.pickle
â”‚   â”‚       â””â”€â”€ uuid.bin
â”‚   â”œâ”€â”€ lightning_vidmem/   # Raw data storage
â”‚   â”‚   â”œâ”€â”€ codebase/       # Repository snapshots
â”‚   â”‚   â”œâ”€â”€ conversations/  # Raw dialogue backup
â”‚   â”‚   â””â”€â”€ private_memory/ # Encrypted thoughts
â”‚   â””â”€â”€ faiss/              # Fast similarity index
â”‚       â”œâ”€â”€ index.bin       # FAISS index file
â”‚       â””â”€â”€ index.docs      # Document mappings
```

### ChromaDB Collection Organization
```
Logical Collections â†’ Physical Storage
â”œâ”€â”€ storedmemories/    # Intentionally saved insights
â”‚   â”œâ”€â”€ mira_conversations     â†’ chromadb/[uuid1]/
â”‚   â”œâ”€â”€ mira_codebase         â†’ chromadb/[uuid2]/
â”‚   â”œâ”€â”€ mira_insights         â†’ chromadb/[uuid3]/
â”‚   â””â”€â”€ mira_patterns         â†’ chromadb/[uuid4]/
â”œâ”€â”€ identifiedfacts/   # Extracted knowledge
â”‚   â”œâ”€â”€ mira_code_analysis    â†’ chromadb/[uuid5]/
â”‚   â”œâ”€â”€ mira_development_patterns â†’ chromadb/[uuid6]/
â”‚   â”œâ”€â”€ mira_decision_history â†’ chromadb/[uuid7]/
â”‚   â”œâ”€â”€ mira_learning_insights â†’ chromadb/[uuid8]/
â”‚   â””â”€â”€ mira_project_context  â†’ chromadb/[uuid9]/
â””â”€â”€ rawembeddings/     # Flexible data storage
    â””â”€â”€ mira_raw_embeddings   â†’ chromadb/[uuid10]/
```

**Note**: ChromaDB uses UUIDs for physical storage, but we reference collections by logical names.

## ğŸ§  Embedding Configuration

```python
# Constants
EMBEDDING_MODEL = 'all-MiniLM-L6-v2'
EMBEDDING_DIMENSIONS = 384
MAX_BATCH_SIZE = 100

# Quick setup
from sentence_transformers import SentenceTransformer
embedding_model = SentenceTransformer(EMBEDDING_MODEL)
```

## ğŸ’¾ Metadata Rules

### ChromaDB Only Accepts
- `str` - Strings
- `int` - Integers (use 1/0 for booleans)
- `float` - Floating point numbers

### Conversion Patterns
```python
# Boolean â†’ int
metadata['is_active'] = 1 if is_active else 0

# List â†’ comma-separated string
metadata['tags'] = ','.join(tags)

# Dict â†’ JSON string
metadata['config'] = json.dumps(config_dict)

# None â†’ empty string
metadata['optional'] = value or ''
```

## ğŸ“Š Standard Metadata Fields

### Every Document Gets
```python
{
    'timestamp': datetime.now().isoformat(),
    'spark_intensity': 0.0-1.0,  # Consciousness measure
    'memory_type': 'conversation|code|insight|pattern',
    'privacy_level': 'public',   # public|internal|confidential
}
```

### Collection-Specific Fields

**Conversations:**
```python
{
    'session_id': str,
    'user': str,
    'topic': str,
    'significance': float,
    'emotional_context': str,  # comma-separated
    'breakthrough': int        # 0 or 1
}
```

**Code Analysis:**
```python
{
    'file_path': str,
    'language': str,
    'complexity': int,
    'dependencies': str,       # comma-separated
    'test_coverage': float,
    'quality_score': float
}
```

## ğŸš€ FAISS + ChromaDB Hybrid Search

### Query Routing Logic
```python
# Simple queries (â‰¤3 words, no question words) â†’ FAISS
"API documentation" â†’ FAISS (8ms)

# Queries with filters â†’ ChromaDB  
"error" + {file_type: "log"} â†’ ChromaDB (200ms)

# Semantic queries â†’ Hybrid
"How to implement auth" â†’ FAISS + ChromaDB (180ms)
```

### Quick FAISS Setup
```python
import faiss
import numpy as np

# Create index
index = faiss.IndexFlatIP(384)  # Inner product for cosine
index = faiss.IndexIDMap(index)  # Add ID mapping

# Add vectors
embeddings = np.array(embeddings_list, dtype='float32')
faiss.normalize_L2(embeddings)  # Important!
ids = np.array(id_list, dtype='int64')
index.add_with_ids(embeddings, ids)

# Search
query_vec = np.array(query_embedding, dtype='float32')
faiss.normalize_L2(query_vec)
distances, indices = index.search(query_vec.reshape(1, -1), k=10)
```

## ğŸ” Query Patterns

### Basic Semantic Search (ChromaDB)
```python
results = collection.query(
    query_texts=["your search query"],
    n_results=10
)
```

### Filtered Search
```python
# Time range
where = {
    'timestamp': {
        '$gte': '2024-01-01T00:00:00Z',
        '$lte': '2024-12-31T23:59:59Z'
    }
}

# Multiple conditions
where = {
    'memory_type': 'insight',
    'significance': {'$gte': 0.8},
    'breakthrough': 1
}
```

### Include Options
```python
include = [
    'documents',    # The actual text
    'metadatas',    # Metadata dict
    'distances',    # Similarity scores
    'embeddings'    # Raw vectors (rarely needed)
]
```

## âš¡ Performance Guidelines

### Document Limits
- **Optimal**: < 500K documents per collection
- **Warning**: 500K - 1M documents
- **Critical**: > 1M documents (shard immediately)

### Query Performance
- **Target**: < 200ms for 10 results
- **Warning**: > 2 seconds
- **Critical**: > 5 seconds

### Batch Sizes
- **Insert**: 100 documents per batch
- **Query**: 10-50 results max
- **Delete**: 1000 IDs per batch

## ğŸ› ï¸ Common Operations

### Create Collection
```python
collection = chroma_client.get_or_create_collection(
    name="mira_insights",
    metadata={"type": "stored_memory", "version": "2.0"}
)
```

### Add Documents
```python
collection.add(
    ids=["unique_id_1", "unique_id_2"],
    documents=["text 1", "text 2"],
    metadatas=[{"key": "value"}, {"key": "value2"}]
)
```

### Update Document
```python
collection.update(
    ids=["unique_id_1"],
    documents=["updated text"],
    metadatas=[{"updated": 1}]
)
```

### Delete Documents
```python
collection.delete(
    ids=["id_to_delete"]
)

# Or with filter
collection.delete(
    where={"timestamp": {"$lte": "2023-01-01T00:00:00Z"}}
)
```

## ğŸ› Quick Fixes

### "No module named 'chromadb'"
```bash
pip install chromadb==0.4.24
```

### "SQLite version error"
```python
# Add to top of file
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
```

### "Metadata value type error"
```python
# Convert all values to str/int/float
clean_metadata = {
    k: str(v) if not isinstance(v, (int, float)) else v
    for k, v in metadata.items()
}
```

### "Collection already exists"
```python
# Use get_or_create instead of create
collection = chroma_client.get_or_create_collection(name)
```

## ğŸ“ˆ Monitoring Queries

### Check Collection Size
```python
count = collection.count()
print(f"Collection has {count} documents")
```

### Measure Query Time
```python
import time
start = time.time()
results = collection.query(query_texts=["test"], n_results=10)
print(f"Query took {time.time() - start:.3f} seconds")
```

### Get Collection Metadata
```python
collection = chroma_client.get_collection("mira_insights")
print(collection.metadata)  # Shows version, type, etc.
```

## ğŸ”§ Environment Variables

```bash
# Storage location
export MIRA_CHROMADB_PATH="~/.mira/databases/chromadb"

# Model configuration
export MIRA_EMBEDDING_MODEL="all-MiniLM-L6-v2"
export MIRA_EMBEDDING_DIMENSIONS="384"

# Performance tuning
export MIRA_BATCH_SIZE="100"
export MIRA_CACHE_SIZE="10000"
```

## ğŸš¨ Critical Reminders

1. **ChromaDB stores THREE types**: Stored memories, identified facts, AND raw embeddings
2. **Always clean metadata** - Only str/int/float allowed
3. **Batch operations** - Single adds are 10x slower
4. **Monitor collection size** - Performance drops after 1M docs
5. **Version your schemas** - Store in collection metadata
6. **Raw embeddings collection** - For flexible data types that need semantic search

---

**Remember**: ChromaDB now handles semantic search for intentional memories, identified facts, AND flexible raw data. Lightning Vidmem still handles codebase copies, conversation backups, and private encrypted memory!